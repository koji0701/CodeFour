# auto generated by Cursor, documented for reference

# Multi-Object Detection Pipeline Usage Guide

## Overview

This pipeline performs **both face and license plate detection** on videos using YOLO models and exports annotations in JSON format for the React video annotation app.

## Getting Started

1. **Install dependencies:**
   ```bash
   cd scripts
   uv sync
   source .venv/bin/activate
   ```

2. **Run the complete pipeline (default - processes all videos):**
   ```bash
   python main.py
   ```

## Main Script Usage

The `main.py` script is the primary interface that always performs both face and license plate detection.

### Basic Usage

```bash
# Process all videos in videos/ directory (default behavior)
python main.py

# Process a specific video file
python main.py --video videos/test.mp4

# Use custom confidence threshold
python main.py --confidence 0.3

# Use custom model paths
python main.py --face-model yolo11m-face.pt --license-model custom-license.pt
```

### Advanced Options

```bash
# Custom input/output directories
python main.py --videos-dir custom_videos --output-dir custom_output

# Full customization example
python main.py \
  --video videos/test.mp4 \
  --confidence 0.25 \
  --face-model scripts/yolo11n-face.pt \
  --license-model scripts/yolov11-license-plate-detection.pt \
  --output-dir assets-json
```

### Command Line Arguments

- `--video, -v`: Process a specific video file (default: process all videos in videos/ directory)
- `--confidence, -c`: Confidence threshold for detections (default: 0.25)
- `--face-model`: Path to face detection model (default: scripts/yolo11n-face.pt)
- `--license-model`: Path to license plate model (default: scripts/yolov11-license-plate-detection.pt)
- `--videos-dir`: Input directory containing videos (default: videos)
- `--output-dir`: Output directory for JSON files (default: assets-json)

## Individual Scripts (Legacy)

### Single Face Detection Only
```bash
# For face-only detection (legacy usage)
python face_detection.py --batch
python face_detection.py --video sample.mp4 --confidence 0.3
```

### Multi-Object Detection (Direct Usage)
```bash
# Direct usage of multi_detection.py (advanced users)
python -c "
from multi_detection import Detector, MultiObjectDetectionProcessor
detectors = [
    Detector('face', 'scripts/yolo11n-face.pt', ['face'], 0.25),
    Detector('license_plate', 'scripts/yolov11-license-plate-detection.pt', ['license_plate'], 0.25)
]
processor = MultiObjectDetectionProcessor(detectors)
processor.process_sample_videos('videos', 'assets-json')
"
```

## Output Format

### JSON Structure
The output JSON includes both detection types with class labels:

```json
{
  "video_info": {
    "filename": "test.mp4",
    "width": 1920,
    "height": 1080,
    "fps": 30,
    "frame_count": 900,
    "duration": 30.0
  },
  "annotations": {
    "0": [
      {
        "id": "face_0_0",
        "x": 0.1,
        "y": 0.2,
        "width": 0.15,
        "height": 0.2,
        "confidence": 0.85,
        "type": "ai-generated",
        "class": "face"
      },
      {
        "id": "license_plate_0_1",
        "x": 0.7,
        "y": 0.8,
        "width": 0.1,
        "height": 0.05,
        "confidence": 0.92,
        "type": "ai-generated",
        "class": "license_plate"
      }
    ]
  }
}
```

### File Locations
- **JSON files**: Saved to `assets-json/` directory
- **Format**: Compatible with React video annotation app
- **Naming**: `{video_name}_annotations.json`

## Model Requirements

Ensure you have the required model files:
- **Face detection**: `scripts/yolo11n-face.pt`
- **License plate detection**: `scripts/yolov11-license-plate-detection.pt`

## Performance Tips

- **Confidence threshold**: 
  - Use `0.1` for more detections (may include false positives)
  - Use `0.5` for fewer, more confident detections
- **Model sizes**: 
  - `yolo11n.pt` (nano): Fastest, least accurate
  - `yolo11s.pt` (small): Balanced speed/accuracy
  - `yolo11m.pt` (medium): Better accuracy, slower
  - `yolo11l.pt` (large): Best accuracy, slowest
- **Hardware**: GPU acceleration is automatic if CUDA is available

## Troubleshooting

### Common Issues
- **Model not found**: Ensure model files exist in the `scripts/` directory
- **No detections**: Try lowering confidence threshold with `--confidence 0.1`
- **Slow processing**: Use smaller model variants (nano/small)
- **Memory issues**: Process videos individually rather than batch processing

### Debug Information
The script provides detailed progress information:
- Model loading confirmation
- Video properties and processing progress
- Detection counts per frame
- Final statistics

## Quick Reference

```bash
# Most common usage - process all videos with both detection types
python main.py

# Process specific video
python main.py --video videos/test.mp4

# Custom confidence
python main.py --confidence 0.3

# Help and options
python main.py --help
```